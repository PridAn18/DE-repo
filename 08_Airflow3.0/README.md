# Apache Airflow 3.0 — Asset-Oriented Data Pipeline

## Обзор проекта

Этот проект демонстрирует реализацию дата-пайплайна с использованием **Apache Airflow 3.0** и его нового **asset-ориентированного подхода**. Он включает в себя извлечение, преобразование и обогащение данных с последующим сохранением в **SQLite** без доступа к файловой системе контейнера.

Данные извлекаются из API [randomuser.me](https://randomuser.me), трансформируются, дополняются вычислением возраста и записываются в локальную БД `/tmp/users.db`.

---

## Используемые фичи Airflow 3.0

| Возможность          | Описание                                                                       |
| -------------------- | ------------------------------------------------------------------------------ |
| `@asset` DAG'и       | Описание зависимостей данных через `schedule=[...]`                            |
| XCom                 | Передача данных между asset'ами через `xcom_pull()` с явным указанием `dag_id` |
| Выделенная логика    | Логика вынесена в чистые функции, которые можно переиспользовать и тестировать |
| Логирование          | Использование встроенного логгера Airflow для прозрачности исполнения          |
| SQLite вместо файлов | Сохранение данных без доступа к директориям — в локальную базу SQLite          |
| Тестируемость        | Логика покрыта автотестами с использованием `pytest`                           |

---

## Запуск проекта локально

### Требования

* Docker
* Astro CLI

### Установка и запуск:

```bash
# Установка Astro CLI
curl -sSL install.astronomer.io | sudo bash -s

# Инициализация проекта
astro dev init

# Запуск локального окружения
astro dev start
```

---

## Архитектура пайплайна

```text
get_data() ➔ format_data() ➔ enrich_and_save()
```

### 1. `get_data`

* Получает одного пользователя из API `randomuser.me`
* Запускается ежедневно
* Результат сохраняется в XCom

### 2. `format_data`

* Выделяет нужные поля, присваивает UUID
* Использует чистую функцию `do_format_data()` для переиспользования
* Зависит от `get_data`

### 3. `enrich_and_save`

* Вычисляет возраст по дате рождения
* Логирует информацию о пользователе
* Сохраняет в SQLite: `/tmp/users.db`

---

## Проверка результата (SQLite)

```bash
# Копирование базы из контейнера на хост
docker cp $(docker ps -qf name=scheduler)://tmp/users.db ./users.db

# Открытие и запрос к базе
sqlite3 users.db
SELECT * FROM users;
```

---

## Тестирование логики

Бизнес-логика (`do_format_data`) вынесена в отдельную функцию и протестирована изолированно.

```bash
# Запуск тестов внутри контейнера
astro dev bash
pytest tests/
```

